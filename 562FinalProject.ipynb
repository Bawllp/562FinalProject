{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OX8vyeuWCYZn",
    "outputId": "f5a65fc4-db16-4a63-8131-363c9cabc318"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from scipy import stats as st\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK38w-xSpwmn"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Global constants. Note that you will change  rare doc frequency threshold and max_features will be programmatically as part of hyperparameter optimization. I've set a default value for testing purposes\n",
    "\n",
    "\n",
    "\n",
    "ENGLISH_STOP_WORDS_MODIFIED =[\n",
    "    'a',\n",
    "    'about',\n",
    "    'above',\n",
    "    'across',\n",
    "    'after',\n",
    "    'afterwards',\n",
    "    #'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'all',\n",
    "    #'almost',\n",
    "    #'alone',\n",
    "    'along',\n",
    "    #'already',\n",
    "    #'also',\n",
    "    #'although',\n",
    "    'always',\n",
    "    'am',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amoungst',\n",
    "    'amount',\n",
    "    'an',\n",
    "    'and',\n",
    "    #'another',\n",
    "    #'any',\n",
    "    'anyhow',\n",
    "    #'anyone',\n",
    "    #'anything',\n",
    "    'anyway',\n",
    "    #'anywhere',\n",
    "    'are',\n",
    "    'aren',\n",
    "    'around',\n",
    "    'as',\n",
    "    'at',\n",
    "    'back',\n",
    "    'be',\n",
    "    'became',\n",
    "    'because',\n",
    "    'become',\n",
    "    'becomes',\n",
    "    'becoming',\n",
    "    'been',\n",
    "    #'before',\n",
    "    'beforehand',\n",
    "    #'behind',\n",
    "    'being',\n",
    "    #'below',\n",
    "    'beside',\n",
    "    'besides',\n",
    "    'between',\n",
    "    #'beyond',\n",
    "    'bill',\n",
    "    'both',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'by',\n",
    "    #'call',\n",
    "    'can',\n",
    "    #'cannot',\n",
    "    #'cant',\n",
    "    'co',\n",
    "    'con',\n",
    "    #'could',\n",
    "    #'couldn',\n",
    "    #'couldnt',\n",
    "    'cry',\n",
    "    'd',\n",
    "    'de',\n",
    "    #'describe',\n",
    "    #'detail',\n",
    "    #'did',\n",
    "    #'didn',\n",
    "    'do',\n",
    "    #'does',\n",
    "    #'doesn',\n",
    "    'doing',\n",
    "    'don',\n",
    "    #'done',\n",
    "    'down',\n",
    "    'due',\n",
    "    'during',\n",
    "    'each',\n",
    "    'eg',\n",
    "    'eight',\n",
    "    'either',\n",
    "    'eleven',\n",
    "    'else',\n",
    "    'elsewhere',\n",
    "    'empty',\n",
    "    #'enough',\n",
    "    'etc',\n",
    "    'even',\n",
    "    'ever',\n",
    "    'every',\n",
    "    'everyone',\n",
    "    'everything',\n",
    "    'everywhere',\n",
    "    #'except',\n",
    "    #'few',\n",
    "    'fifteen',\n",
    "    'fify',\n",
    "    'fill',\n",
    "    #'find',\n",
    "    'fire',\n",
    "    #'first',\n",
    "    'five',\n",
    "    'for',\n",
    "    #'former',\n",
    "    #'formerly',\n",
    "    'forty',\n",
    "    'found',\n",
    "    'four',\n",
    "    'from',\n",
    "    'front',\n",
    "    'full',\n",
    "    #'further',\n",
    "    'get',\n",
    "    'give',\n",
    "    'go',\n",
    "    'had',\n",
    "    'hadn',\n",
    "    #'has',\n",
    "    #'hasn',\n",
    "    #'hasnt',\n",
    "    'have',\n",
    "    'haven',\n",
    "    'having',\n",
    "    'he',\n",
    "    'hence',\n",
    "    'her',\n",
    "    'here',\n",
    "    'hereafter',\n",
    "    'hereby',\n",
    "    'herein',\n",
    "    'hereupon',\n",
    "    'hers',\n",
    "    'herself',\n",
    "    'him',\n",
    "    'himself',\n",
    "    'his',\n",
    "    'how',\n",
    "    #'however',\n",
    "    'hundred',\n",
    "    'i',\n",
    "    'ie',\n",
    "    'if',\n",
    "    'in',\n",
    "    'inc',\n",
    "    'indeed',\n",
    "    'interest',\n",
    "    'into',\n",
    "    'is',\n",
    "    #'isn',\n",
    "    'it',\n",
    "    'its',\n",
    "    'itself',\n",
    "    #'just',\n",
    "    #'keep',\n",
    "    #'last',\n",
    "    'latter',\n",
    "    'latterly',\n",
    "    #'least',\n",
    "    #'less',\n",
    "    'll',\n",
    "    'ltd',\n",
    "    'm',\n",
    "    'ma',\n",
    "    #'made',\n",
    "    #'many',\n",
    "    'may',\n",
    "    'me',\n",
    "    'meanwhile',\n",
    "    'might',\n",
    "    'mightn',\n",
    "    'mill',\n",
    "    'mine',\n",
    "    #'more',\n",
    "    #'moreover',\n",
    "    #'most',\n",
    "    #'mostly',\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    'my',\n",
    "    'myself',\n",
    "    'name',\n",
    "    #'namely',\n",
    "    #'needn',\n",
    "    #'neither',\n",
    "    #'never',\n",
    "    #'nevertheless',\n",
    "    #'next',\n",
    "    'nine',\n",
    "    'no',\n",
    "    #'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    #'nothing',\n",
    "    'now',\n",
    "    'nowhere',\n",
    "    'o',\n",
    "    'of',\n",
    "    'off',\n",
    "    'often',\n",
    "    'on',\n",
    "    'once',\n",
    "    'one',\n",
    "    'only',\n",
    "    'onto',\n",
    "    'or',\n",
    "    'other',\n",
    "    #'others',\n",
    "    #'otherwise',\n",
    "    'our',\n",
    "    'ours',\n",
    "    'ourselves',\n",
    "    'out',\n",
    "    'over',\n",
    "    'own',\n",
    "    'part',\n",
    "    'per',\n",
    "    'perhaps',\n",
    "    'please',\n",
    "    'put',\n",
    "    #'rather',\n",
    "    're',\n",
    "    's',\n",
    "    'same',\n",
    "    #'see',\n",
    "    #'seemed',\n",
    "    #'seeming',\n",
    "    #'seems',\n",
    "    #'serious',\n",
    "    #'several',\n",
    "    'shan',\n",
    "    'she',\n",
    "    'should',\n",
    "    'shouldn',\n",
    "    'show',\n",
    "    'side',\n",
    "    'since',\n",
    "    'sincere',\n",
    "    'six',\n",
    "    'sixty',\n",
    "    'so',\n",
    "    'some',\n",
    "    'somehow',\n",
    "    'someone',\n",
    "    'something',\n",
    "    'sometime',\n",
    "    'sometimes',\n",
    "    'somewhere',\n",
    "    'still',\n",
    "    'such',\n",
    "    'system',\n",
    "    't',\n",
    "    'take',\n",
    "    'ten',\n",
    "    'than',\n",
    "    'that',\n",
    "    'the',\n",
    "    'their',\n",
    "    'theirs',\n",
    "    'them',\n",
    "    'themselves',\n",
    "    'then',\n",
    "    'thence',\n",
    "    'there',\n",
    "    'thereafter',\n",
    "    'thereby',\n",
    "    'therefore',\n",
    "    'therein',\n",
    "    'thereupon',\n",
    "    'these',\n",
    "    'they',\n",
    "    'thick',\n",
    "    'thin',\n",
    "    'third',\n",
    "    'this',\n",
    "    'those',\n",
    "    'though',\n",
    "    'three',\n",
    "    'through',\n",
    "    'throughout',\n",
    "    'thru',\n",
    "    'thus',\n",
    "    'to',\n",
    "    'together',\n",
    "    'too',\n",
    "    #'top',\n",
    "    'toward',\n",
    "    'towards',\n",
    "    'twelve',\n",
    "    'twenty',\n",
    "    'two',\n",
    "    'un',\n",
    "    'under',\n",
    "    'until',\n",
    "    'up',\n",
    "    'u',  #added\n",
    "    'wa', #added\n",
    "    'upon',\n",
    "    'us',\n",
    "    've',\n",
    "    #'very',\n",
    "    'via',\n",
    "    'was',\n",
    "    'wasn',\n",
    "    'we',\n",
    "    'well',\n",
    "    'were',\n",
    "    'weren',\n",
    "    'what',\n",
    "    'whatever',\n",
    "    'when',\n",
    "    'whence',\n",
    "    'whenever',\n",
    "    'where',\n",
    "    'whereafter',\n",
    "    'whereas',\n",
    "    'whereby',\n",
    "    'wherein',\n",
    "    'whereupon',\n",
    "    'wherever',\n",
    "    'whether',\n",
    "    'which',\n",
    "    'while',\n",
    "    'whither',\n",
    "    'who',\n",
    "    'whoever',\n",
    "    'whole',\n",
    "    'whom',\n",
    "    'whose',\n",
    "    'why',\n",
    "    'will',\n",
    "    'with',\n",
    "    'within',\n",
    "    'without',\n",
    "    'won',\n",
    "    #'would',\n",
    "    #'wouldn',\n",
    "    'y',\n",
    "    'yet',\n",
    "    'you',\n",
    "    'your',\n",
    "    'yours',\n",
    "    'yourself',\n",
    "    'yourselves'\n",
    "]\n",
    "\n",
    "# Note; I couldn't figure out how to get the manual features added. I use sklearn vectorizer classes for extracting text features, and I don't know how to easily add manual features.\n",
    "# If you know how to do this, and in a way that allows those features to avoid the cutoffs due to min/max document frequency//top N features then please add the below in. If we really need to,\n",
    "# we can do a very roundabout way by making another vectorizer that is run only on text with these features in it, then applying that vectorizer via the .transform() method to our text data, and\n",
    "# then concatenating the datasets.\n",
    "MANUAL_FEATURES = [\n",
    "    \"cannot\", \"unconvinced\", \"needs\", \"unclear\", \"already\", \"how will\", \"how do\", \"unlikely\", \"why don't\", \"is not novel work\", \"isn't novel\", \"is novel work\", \"novel work\", \"is novel\", \"an accept\", \"a reject\", \"convincing\", \"interesting\"] # TODO RETURN TO if time\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return ([self.wnl.lemmatize(t) for t in word_tokenize(doc)])\n",
    "RARE_DOCUMENT_FREQUENCY_THRESHOLD = 1  # TODO produce multiple datasets for multiple values of this threshold\n",
    "MAX_FEATURES = 2000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys6exYQ_zWaI"
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "  df = pd.read_csv(path)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjFjC2P7CtRg"
   },
   "outputs": [],
   "source": [
    "def preprocess(df, column):\n",
    "  df = df.dropna(subset=[column]).reset_index(drop=True)\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "\n",
    "  cleaned = []\n",
    "  for review in df[column]:\n",
    "    temp = review.lower()\n",
    "    temp = temp.replace('\\n', ' ')\n",
    "    temp = temp.replace(',', ' ')\n",
    "    temp = temp.replace('.', ' ')\n",
    "    temp = temp.replace('!', ' ')\n",
    "    temp = temp.replace('?', ' ')\n",
    "    temp = temp.replace(':', ' ')\n",
    "    temp = temp.replace(';', ' ')\n",
    "    temp = [lemmatizer.lemmatize(word) for word in temp.split() if word not in stop_words]\n",
    "    temp = ' '.join(temp)\n",
    "    cleaned.append(temp)\n",
    "  df[column] = cleaned\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8qtU86-mJC1"
   },
   "outputs": [],
   "source": [
    "data_as_given = read_data('data_reviews_filtered.csv')\n",
    "data_as_given = preprocess(data_as_given, 'comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "Nh60iNHQ-ppo",
    "outputId": "3103482d-3797-499c-abc4-862d2d75497a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data_as_given\",\n  \"rows\": 1179,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 340,\n        \"min\": 0,\n        \"max\": 1178,\n        \"num_unique_values\": 1179,\n        \"samples\": [\n          210,\n          58,\n          671\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accepted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 348,\n        \"samples\": [\n          \"Learning to Compose Words into Sentences with Reinforcement Learning\",\n          \"Towards an automatic Turing test: Learning to evaluate dialogue responses\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1177,\n        \"samples\": [\n          \"key detail paper poorly explained even explained model sound interesting may something good published current form specific comment description r_l pi convolution section 2 1 unclear specifically confident understood label pi represented description saen structure section 2 2 worded poorly understanding based equation 1 'shift' operation simply summation representation member object 'aggregate' operation simply concatenates representation multiple relation 'shift' step seems appropriate average object's member's representation h_j rather sum compression technique presented section 2 3 requires multiple object level representation would ever occur given representation real valued high-dimensional text unintelligible \\\"two object equivalent made set part pi-parameterizations r_l pi decomposition relation \\\" 'ego graph patterns' figure 1 'ego graph neural network' used experiment never explained text reference given cannot comment quality experiment\",\n          \"paper provides simple method handle action repetition make action tuple (a x) action chosen x number repetition overall report improvement a3c/ddpg dramatic game moderate idea seems natural wealth experiment support comment - score reported a3c paper mnih et al publication (table s3) differ significantly discrepancy come different training regime (fewer iteration instance) author confirm running replication setting mnih et al provide similar result - intriguing best result figar reported game action repeat dominate seems imply performance overhead figar a3c high since a3c us action repeat 4 (and therefore 4 time fewer gradient updates) a3c could run comparable computation cost lower action repeat would probably result increased performance a3c nevertheless automatic determination appropriate action repeat interesting even overall message seems repeat action often - slightly problematic notation r sometimes denotes reward sometimes denotes element repetition set r (top page 5) - equation bottom page 5 - since sum indexed decision step time step reward r_k modified sum reward (appropriately discounted) time step - section ddpg confusingly written \\\"concatenating\\\" loss strange operation figar correspond loss roughly look like q(x mu(x)) + r log p(x) (with separate loss learning critic) feel reinforce applied repetition variable x (second term sum) reparametrization action (first term) - 'name_this_game' name table intentional - potential weakness method agent must decide commit action fixed number step independently happens next author considered scheme time step agent decides stick current decision (it feel like might relatively simple modification figar)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scoreconf_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5861723029988057,\n        \"min\": 1.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 10,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conf_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7513223041397186,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data_as_given"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8ca9d163-d137-483a-85df-0dbf25d55b85\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accepted</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>scoreconf_score</th>\n",
       "      <th>score</th>\n",
       "      <th>conf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Boosted Residual Networks</td>\n",
       "      <td>author mention aiming sota result however ense...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Boosted Residual Networks</td>\n",
       "      <td>paper proposes boosting based ensemble procedu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Boosted Residual Networks</td>\n",
       "      <td>paper consideration proposes set procedure inc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Boosted Residual Networks</td>\n",
       "      <td>- give detail experiment setup e g parameter t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Deep Learning with Dynamic Computation Graphs</td>\n",
       "      <td>paper describes novel technique improve effici...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ca9d163-d137-483a-85df-0dbf25d55b85')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8ca9d163-d137-483a-85df-0dbf25d55b85 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8ca9d163-d137-483a-85df-0dbf25d55b85');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-261f2cbe-4f4e-4bad-b3a7-2b239736775a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-261f2cbe-4f4e-4bad-b3a7-2b239736775a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-261f2cbe-4f4e-4bad-b3a7-2b239736775a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Unnamed: 0  accepted                                          title  \\\n",
       "0           0         0                      Boosted Residual Networks   \n",
       "1           1         0                      Boosted Residual Networks   \n",
       "2           2         0                      Boosted Residual Networks   \n",
       "3           3         0                      Boosted Residual Networks   \n",
       "4           4         1  Deep Learning with Dynamic Computation Graphs   \n",
       "\n",
       "                                            comments  scoreconf_score  score  \\\n",
       "0  author mention aiming sota result however ense...              NaN    4.0   \n",
       "1  paper proposes boosting based ensemble procedu...              NaN    3.0   \n",
       "2  paper consideration proposes set procedure inc...              NaN    3.0   \n",
       "3  - give detail experiment setup e g parameter t...              NaN    NaN   \n",
       "4  paper describes novel technique improve effici...              NaN    8.0   \n",
       "\n",
       "   conf_score  \n",
       "0         5.0  \n",
       "1         5.0  \n",
       "2         5.0  \n",
       "3         NaN  \n",
       "4         3.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_given['accepted'] = data_as_given['accepted'].astype(str).str.strip().str.capitalize()\n",
    "data_as_given['accepted'] = data_as_given['accepted'].map({'True': 1, 'False': 0})\n",
    "data_as_given.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxJR0yszmYv_"
   },
   "outputs": [],
   "source": [
    "x_data = data_as_given['comments']\n",
    "y_data = data_as_given['accepted']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "ct_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words=ENGLISH_STOP_WORDS_MODIFIED, min_df=RARE_DOCUMENT_FREQUENCY_THRESHOLD, max_features=MAX_FEATURES, ngram_range=(1,3))\n",
    "tf_vect = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words = ENGLISH_STOP_WORDS_MODIFIED, min_df=RARE_DOCUMENT_FREQUENCY_THRESHOLD, max_features=MAX_FEATURES, ngram_range=(1,3), use_idf=False)\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words = ENGLISH_STOP_WORDS_MODIFIED, min_df=RARE_DOCUMENT_FREQUENCY_THRESHOLD, max_features=MAX_FEATURES, ngram_range=(1,3), use_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRyU_wmwy8LR"
   },
   "outputs": [],
   "source": [
    "def svm_train(df, vectorizer, x_train, x_test, y_train, y_test, C, coef0, degree, gamma, kernel):\n",
    "  x_train = vectorizer.fit_transform(x_train)\n",
    "  x_test = vectorizer.transform(x_test)\n",
    "\n",
    "  svm = SVC(C = C, coef0 = coef0, degree = degree, gamma = gamma, kernel=kernel)\n",
    "  svm.fit(x_train, y_train)\n",
    "  y_pred = svm.predict(x_test)\n",
    "\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  cv_results_f1 = cross_val_score(svm, x_train, y_train, cv=5, scoring='f1')\n",
    "  print(\"CV F1 Score:\", cv_results_f1.mean())\n",
    "  cv_results_acc = cross_val_score(svm, x_train, y_train, cv=5, scoring='accuracy')\n",
    "  print(\"CV Accuracy Score:\", cv_results_acc.mean())\n",
    "\n",
    "  return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxLDLaDGugZ3"
   },
   "outputs": [],
   "source": [
    "def rf_train(df, vectorizer, x_train, x_test, y_train, y_test, n_estimators, criterion, max_features, max_depth, bootstrap):\n",
    "  x_train = vectorizer.fit_transform(x_train)\n",
    "  x_test = vectorizer.transform(x_test)\n",
    "\n",
    "  rf = RandomForestClassifier(class_weight='balanced', n_estimators= n_estimators, criterion= criterion, max_features= max_features, max_depth= max_depth, bootstrap= bootstrap)\n",
    "  rf.fit(x_train, y_train)\n",
    "  y_pred = rf.predict(x_test)\n",
    "\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  cv_results_f1 = cross_val_score(rf, x_train, y_train, cv=5, scoring='f1')\n",
    "  print(\"CV F1 Score:\", cv_results_f1.mean())\n",
    "  cv_results_acc = cross_val_score(rf, x_train, y_train, cv=5, scoring='accuracy')\n",
    "  print(\"CV Accuracy Score:\", cv_results_acc.mean())\n",
    "\n",
    "  return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xz11fm3VukW2"
   },
   "outputs": [],
   "source": [
    "def lr_train(df, vectorizer, x_train, x_test, y_train, y_test, penalty, C, max_iter, solver):\n",
    "  x_train = vectorizer.fit_transform(x_train)\n",
    "  x_test = vectorizer.transform(x_test)\n",
    "\n",
    "  lr = LogisticRegression(penalty = penalty, C = C, max_iter = max_iter, solver = solver)\n",
    "  lr.fit(x_train, y_train)\n",
    "  y_pred = lr.predict(x_test)\n",
    "\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  cv_results_f1 = cross_val_score(lr, x_train, y_train, cv=5, scoring='f1')\n",
    "  print(\"CV F1 Score:\", cv_results_f1.mean())\n",
    "  cv_results_acc = cross_val_score(lr, x_train, y_train, cv=5, scoring='accuracy')\n",
    "  print(\"CV Accuracy Score:\", cv_results_acc.mean())\n",
    "\n",
    "  return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d12hfig03kP"
   },
   "outputs": [],
   "source": [
    "def grid_search(svm, x_train, y_train):\n",
    "  param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'gamma': ['scale', 'auto'], 'degree': [2, 3, 4, 5], 'coef0': [0.0, 0.1, 0.5, 1.0]}\n",
    "  grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "\n",
    "  grid_search.fit(x_train, y_train)\n",
    "  print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pha5v5krHcXf"
   },
   "outputs": [],
   "source": [
    "def grid_search_rf(rf, x_train, y_train):\n",
    "  param_grid = {\n",
    "    'n_estimators': [25, 40, 50],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_features': ['log2', 'sqrt'],\n",
    "    'max_depth': [2,4],\n",
    "    'bootstrap': [True, False]\n",
    "    }\n",
    "  grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "\n",
    "  grid_search.fit(x_train, y_train)\n",
    "  print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qskmQgVALREO"
   },
   "outputs": [],
   "source": [
    "def grid_search_lr(rf, x_train, y_train):\n",
    "  param_grid = {'penalty':['l2'],'C':[1, 10, 100], 'max_iter': [100, 200, 500, 1000], 'solver': ['lbfgs', 'saga', 'liblinear']}\n",
    "  grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "\n",
    "  grid_search.fit(x_train, y_train)\n",
    "  print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbQi4HXMsA0U",
    "outputId": "340ad6af-a710-4ea0-8959-267e0f8530b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.673728813559322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       124\n",
      "           1       0.69      0.57      0.62       112\n",
      "\n",
      "    accuracy                           0.67       236\n",
      "   macro avg       0.68      0.67      0.67       236\n",
      "weighted avg       0.68      0.67      0.67       236\n",
      "\n",
      "[[95 29]\n",
      " [48 64]]\n",
      "CV F1 Score: 0.5157421573859929\n",
      "CV Accuracy Score: 0.6351908139142182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5254237288135594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69       124\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.53       236\n",
      "   macro avg       0.26      0.50      0.34       236\n",
      "weighted avg       0.28      0.53      0.36       236\n",
      "\n",
      "[[124   0]\n",
      " [112   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.0\n",
      "CV Accuracy Score: 0.5885511651469099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5254237288135594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69       124\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.53       236\n",
      "   macro avg       0.26      0.50      0.34       236\n",
      "weighted avg       0.28      0.53      0.36       236\n",
      "\n",
      "[[124   0]\n",
      " [112   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.0\n",
      "CV Accuracy Score: 0.5885511651469099\n"
     ]
    }
   ],
   "source": [
    "svm_ct = svm_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, 10, 1.0, 2, 'auto', 'poly')\n",
    "svm_tf = svm_train(data_as_given, tf_vect, x_train, x_test, y_train, y_test, 10, 1.0, 2, 'auto', 'poly')\n",
    "svm_tfidf = svm_train(data_as_given, tfidf_vect, x_train, x_test, y_train, y_test, 10, 1.0, 2, 'auto', 'poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQHIs0RXs5C9",
    "outputId": "f356ce83-e562-437f-aa26-9bbcf93256fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_train_ct = ct_vectorizer.fit_transform(x_train)\n",
    "x_train_tf = tf_vect.fit_transform(x_train)\n",
    "x_train_idf = tfidf_vect.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCSrtlHyYi0p",
    "outputId": "068ae09f-2a58-4745-c905-d18ee09fbd5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'coef0': 1.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Best parameters: {'C': 1, 'coef0': 1.0, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Best parameters: {'C': 10, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "grid_search(svm_ct, x_train_ct, y_train)\n",
    "grid_search(svm_tf, x_train_tf, y_train)\n",
    "grid_search(svm_tfidf, x_train_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqvx2Cc6FX7I",
    "outputId": "eef30475-9525-4b49-f0f0-2b40f4fa8593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.673728813559322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       124\n",
      "           1       0.69      0.57      0.62       112\n",
      "\n",
      "    accuracy                           0.67       236\n",
      "   macro avg       0.68      0.67      0.67       236\n",
      "weighted avg       0.68      0.67      0.67       236\n",
      "\n",
      "[[95 29]\n",
      " [48 64]]\n",
      "CV F1 Score: 0.5157421573859929\n",
      "CV Accuracy Score: 0.6351908139142182\n",
      "tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.652542372881356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.75      0.69       124\n",
      "           1       0.66      0.54      0.60       112\n",
      "\n",
      "    accuracy                           0.65       236\n",
      "   macro avg       0.65      0.65      0.65       236\n",
      "weighted avg       0.65      0.65      0.65       236\n",
      "\n",
      "[[93 31]\n",
      " [51 61]]\n",
      "CV F1 Score: 0.5394243445295472\n",
      "CV Accuracy Score: 0.6521501744906\n",
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6779661016949152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.74       124\n",
      "           1       0.79      0.44      0.56       112\n",
      "\n",
      "    accuracy                           0.68       236\n",
      "   macro avg       0.71      0.67      0.65       236\n",
      "weighted avg       0.71      0.68      0.66       236\n",
      "\n",
      "[[111  13]\n",
      " [ 63  49]]\n",
      "CV F1 Score: 0.4571811637295301\n",
      "CV Accuracy Score: 0.6691489361702129\n"
     ]
    }
   ],
   "source": [
    "print(\"ct\")\n",
    "svm_ct_tuned = svm_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, 10, 1.0, 2, 'auto', 'poly')\n",
    "print(\"tf\")\n",
    "svm_tf_tuned = svm_train(data_as_given, tf_vect, x_train, x_test, y_train, y_test, 1, 1.0, 3, 'scale', 'poly')\n",
    "print(\"tfidf\")\n",
    "svm_tfidf_tuned = svm_train(data_as_given, tfidf_vect, x_train, x_test, y_train, y_test, 10, 0.0, 2, 'scale', 'poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkxJxITC_lOM",
    "outputId": "37170906-e57f-4cde-b8d1-20d03a1795e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6228813559322034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61       124\n",
      "           1       0.59      0.69      0.63       112\n",
      "\n",
      "    accuracy                           0.62       236\n",
      "   macro avg       0.63      0.63      0.62       236\n",
      "weighted avg       0.63      0.62      0.62       236\n",
      "\n",
      "[[70 54]\n",
      " [35 77]]\n",
      "CV F1 Score: 0.5206743031943518\n",
      "CV Accuracy Score: 0.5779635258358663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.597457627118644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.73      0.65       124\n",
      "           1       0.60      0.46      0.52       112\n",
      "\n",
      "    accuracy                           0.60       236\n",
      "   macro avg       0.60      0.59      0.59       236\n",
      "weighted avg       0.60      0.60      0.59       236\n",
      "\n",
      "[[90 34]\n",
      " [61 51]]\n",
      "CV F1 Score: 0.5334737659194586\n",
      "CV Accuracy Score: 0.5716030620285939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.559322033898305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59       124\n",
      "           1       0.54      0.50      0.52       112\n",
      "\n",
      "    accuracy                           0.56       236\n",
      "   macro avg       0.56      0.56      0.56       236\n",
      "weighted avg       0.56      0.56      0.56       236\n",
      "\n",
      "[[76 48]\n",
      " [56 56]]\n",
      "CV F1 Score: 0.49018464697393\n",
      "CV Accuracy Score: 0.5641224811437577\n",
      "Best parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 40}\n",
      "Best parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 40}\n",
      "Best parameters: {'bootstrap': False, 'criterion': 'log_loss', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "rf_ct = rf_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, 25, 'gini', 'sqrt', 2, False)\n",
    "rf_tf = rf_train(data_as_given, tf_vect, x_train, x_test, y_train, y_test, 25, 'gini', 'sqrt', 2, False)\n",
    "rf_tfidf = rf_train(data_as_given, tfidf_vect, x_train, x_test, y_train, y_test, 25, 'gini', 'sqrt', 2, False)\n",
    "\n",
    "grid_search_rf(rf_ct, x_train_ct, y_train)\n",
    "grid_search_rf(rf_tf, x_train_tf, y_train)\n",
    "grid_search_rf(rf_tfidf, x_train_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWtAnEYfsdVQ",
    "outputId": "8a069c31-7a33-44dc-d151-90a3b9a4d5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6440677966101694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64       124\n",
      "           1       0.61      0.70      0.65       112\n",
      "\n",
      "    accuracy                           0.64       236\n",
      "   macro avg       0.65      0.65      0.64       236\n",
      "weighted avg       0.65      0.64      0.64       236\n",
      "\n",
      "[[74 50]\n",
      " [34 78]]\n",
      "CV F1 Score: 0.5244967135332829\n",
      "CV Accuracy Score: 0.5895474501857481\n",
      "tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5720338983050848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.62       124\n",
      "           1       0.56      0.46      0.50       112\n",
      "\n",
      "    accuracy                           0.57       236\n",
      "   macro avg       0.57      0.57      0.56       236\n",
      "weighted avg       0.57      0.57      0.57       236\n",
      "\n",
      "[[84 40]\n",
      " [61 51]]\n",
      "CV F1 Score: 0.4847499913436065\n",
      "CV Accuracy Score: 0.5799898682877406\n",
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6398305084745762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67       124\n",
      "           1       0.63      0.57      0.60       112\n",
      "\n",
      "    accuracy                           0.64       236\n",
      "   macro avg       0.64      0.64      0.64       236\n",
      "weighted avg       0.64      0.64      0.64       236\n",
      "\n",
      "[[87 37]\n",
      " [48 64]]\n",
      "CV F1 Score: 0.5032652283074774\n",
      "CV Accuracy Score: 0.6171788810086684\n"
     ]
    }
   ],
   "source": [
    "print(\"ct\")\n",
    "rf_ct = rf_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, 40, 'gini', 'log2', 4, False)\n",
    "print(\"tf\")\n",
    "rf_tf = rf_train(data_as_given, tf_vect, x_train, x_test, y_train, y_test, 40, 'gini', 'sqrt', 2, True)\n",
    "print(\"tfidf\")\n",
    "rf_tfidf = rf_train(data_as_given, tfidf_vect, x_train, x_test, y_train, y_test, 50, 'log_loss', 'sqrt', 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqLXAJRZvCS4",
    "outputId": "5b86e99a-a7b0-405c-98ad-0f31f5afd320"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.635593220338983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68       124\n",
      "           1       0.64      0.54      0.58       112\n",
      "\n",
      "    accuracy                           0.64       236\n",
      "   macro avg       0.64      0.63      0.63       236\n",
      "weighted avg       0.64      0.64      0.63       236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.5403566724619356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy Score: 0.6489643138579309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6483050847457628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68       124\n",
      "           1       0.64      0.59      0.61       112\n",
      "\n",
      "    accuracy                           0.65       236\n",
      "   macro avg       0.65      0.65      0.65       236\n",
      "weighted avg       0.65      0.65      0.65       236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.5342545622824171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy Score: 0.6362490149724193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6779661016949152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       124\n",
      "           1       0.68      0.61      0.64       112\n",
      "\n",
      "    accuracy                           0.68       236\n",
      "   macro avg       0.68      0.67      0.67       236\n",
      "weighted avg       0.68      0.68      0.68       236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.5404673917432106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy Score: 0.6447258808960937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "lr_ct = lr_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, None, 10, 100, 'saga')\n",
    "lr_tf = lr_train(data_as_given, tf_vect, x_train, x_test, y_train, y_test, None, 10, 100, 'saga')\n",
    "lr_tfidf = lr_train(data_as_given, tfidf_vect, x_train, x_test, y_train, y_test, None, 10, 100, 'saga')\n",
    "\n",
    "grid_search_lr(lr_ct, x_train_ct, y_train)\n",
    "grid_search_lr(lr_tf, x_train_tf, y_train)\n",
    "grid_search_lr(lr_tfidf, x_train_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hgb-kXRJs60k",
    "outputId": "c88f19a1-e596-4ea8-feb1-652f9152b723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6398305084745762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       124\n",
      "           1       0.63      0.58      0.60       112\n",
      "\n",
      "    accuracy                           0.64       236\n",
      "   macro avg       0.64      0.64      0.64       236\n",
      "weighted avg       0.64      0.64      0.64       236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.5589471404503066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy Score: 0.652167060677699\n",
      "tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6440677966101694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       124\n",
      "           1       0.64      0.56      0.60       112\n",
      "\n",
      "    accuracy                           0.64       236\n",
      "   macro avg       0.64      0.64      0.64       236\n",
      "weighted avg       0.64      0.64      0.64       236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.5504110954079418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy Score: 0.6479004840706969\n",
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6313559322033898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67       124\n",
      "           1       0.63      0.54      0.58       112\n",
      "\n",
      "    accuracy                           0.63       236\n",
      "   macro avg       0.63      0.63      0.63       236\n",
      "weighted avg       0.63      0.63      0.63       236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: 0.5432860050932179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy Score: 0.6489643138579309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"ct\")\n",
    "lr_ct = lr_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, 'l2', 1, 1000, 'saga')\n",
    "print(\"tf\")\n",
    "lr_tf = lr_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, 'l2', 10, 200, 'saga')\n",
    "print(\"tfidf\")\n",
    "lr_tfidf = lr_train(data_as_given, ct_vectorizer, x_train, x_test, y_train, y_test, 'l2', 10, 100, 'saga')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
